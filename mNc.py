import sys
import os
import time
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from enum import Enum, auto
from typing import List, Optional, Dict
from collections import defaultdict

# å°è¯•å¯¼å…¥ pyperclipï¼Œå¦‚æœå¤±è´¥åˆ™è®¾ç½®æ ‡è®°
try:
    import pyperclip
    PYPERCLIP_AVAILABLE = True
except ImportError:
    PYPERCLIP_AVAILABLE = False

# --- å¸¸é‡å®šä¹‰ ---

# [æ˜¾ç¤ºé…ç½®]
# å®æ—¶è¾“å‡ºæ—¶ï¼Œç”¨äºæ˜¾ç¤ºæ–‡ä»¶è·¯å¾„çš„æœ€å¤§å­—ç¬¦é•¿åº¦ã€‚è¶…è¿‡æ­¤é•¿åº¦çš„è·¯å¾„ä¸­é—´ä¼šæ˜¾ç¤ºä¸º...
MAX_PATH_DISPLAY_LEN = 80

# [æ–‡ä»¶è¿‡æ»¤]
# å®šä¹‰å•ä¸ªæ–‡ä»¶çš„æœ€å¤§ä½“ç§¯ï¼ˆ20MBï¼‰ã€‚è¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶å°†è¢«ç›´æ¥è·³è¿‡ï¼Œä¸è¿›è¡Œä»»ä½•è¯»å–æˆ–åˆ†æã€‚
# ç›®çš„æ˜¯ä¸ºäº†é˜²æ­¢å› æ„å¤–æ‹–å…¥è¶…å¤§æ–‡ä»¶ï¼ˆå¦‚è§†é¢‘ã€æ•°æ®åº“ï¼‰å¯¼è‡´ç¨‹åºå†…å­˜æº¢å‡ºæˆ–é•¿æ—¶é—´æ— å“åº”ã€‚
MAX_FILE_SIZE_BYTES = 20 * 1024 * 1024

# [å¼ºåˆ¶æ–‡æœ¬è¯»å– / ç™½åå•é…ç½®]
# å¼ºåˆ¶ä»¥æ–‡æœ¬æ–¹å¼è¯»å–çš„æ–‡ä»¶åç¼€ååˆ—è¡¨ (ç™½åå•æ¨¡å¼)
# åªæœ‰åœ¨æ­¤åˆ—è¡¨ä¸­çš„åç¼€åæ‰ä¼šè¢«è¯»å–
# "*" è¡¨ç¤ºæ— åç¼€çš„æ–‡ä»¶
FORCE_TEXT_EXTENSIONS = {
    # --- æ’é™¤çš„åç¼€ (åŸ TEMP_FILE_PATTERNS å†…å®¹) ---
    # .pyc, .pyo, .pyd, __pycache__, .DS_Store, Thumbs.db
    # .o, .obj, .class, .log, .tmp, .temp, .swp, .swo, ~
    # .lock, package-lock.json, yarn.lock, poetry.lock, Pipfile.lock
    
    # --- é€šç”¨æ–‡æœ¬ ---
    '.txt', '.md', '.markdown', '.rst', '.tex',
    
    # --- å¸¸è§ç¼–ç¨‹è¯­è¨€ ---
    # Python
    '.py', '.pyw', '.pyi',
    # JavaScript/Web
    '.js', '.jsx', '.ts', '.tsx', '.mjs', '.cjs', '.vue',
    '.html', '.htm', '.css', '.scss', '.sass', '.less',
    # Java/JVM
    '.java', '.kt', '.kotlin', '.scala', '.groovy', '.gradle',
    # C/C++
    '.c', '.cpp', '.cc', '.cxx', '.h', '.hpp', '.make', '.cmake',
    # C#/.NET
    '.cs', '.csproj', '.sln', '.vb', '.fs', '.config',
    # Go/Rust/Swift
    '.go', '.rs', '.swift',
    # Shell/Scripting
    '.sh', '.bash', '.zsh', '.bat', '.cmd', '.ps1', '.lua', '.pl', '.pm', '.rb', '.php',
    
    # --- æ•°æ®ä¸é…ç½® ---
    '.json', '.xml', '.yaml', '.yml', '.toml', '.ini', '.conf', '.properties',
    '.sql', '.env', '.gitignore', '.dockerignore', 'Dockerfile',
    
    # --- å…¶å®ƒä¿ç•™ ---
    # '*' # ä¿ç•™åŒ¹é…æ— åç¼€æ–‡ä»¶çš„èƒ½åŠ›
}

# [æ’é™¤è·¯å¾„é…ç½®]
# éœ€è¦æ’é™¤çš„ç›®å½•è·¯å¾„åˆ—è¡¨ï¼ˆæ”¯æŒå¤šçº§è·¯å¾„ï¼‰
EXCLUDED_PATHS = [
    # Python ç›¸å…³
    'venv', 'env', '.venv', '.env',
    'venv/Lib', 'venv/lib', 'env/Lib', 'env/lib', '.venv/Lib', '.venv/lib',
    'venv/Scripts', 'env/Scripts', '.venv/Scripts',
    '__pycache__',
    '.pytest_cache',
    '.tox',
    'dist', 'build',
    '*.egg-info',
    '.mypy_cache',
    '.ruff_cache',
    '.eggs',
    'site-packages',
    
    # JavaScript/Node ç›¸å…³
    'node_modules',
    'node_modules/.bin',
    'node_modules/.cache',
    '.npm',
    '.yarn',
    '.pnp',
    'bower_components',
    'dist', 'build',
    '.next',
    '.nuxt',
    'coverage',
    # 'out',
    '.output',
    
    # Java ç›¸å…³
    # 'target',
    # 'bin',
    '.gradle',
    '.m2',
    
    # .NET ç›¸å…³
    # 'bin',
    # 'obj',
    # 'packages',
    '.vs',
    
    # Ruby ç›¸å…³
    '.bundle',
    'vendor/bundle',
    'vendor/cache',
    
    # Go ç›¸å…³
    'vendor/bundle',
    'vendor/cache',
    
    # Rust ç›¸å…³
    'target/debug',
    'target/release',
    
    # ç‰ˆæœ¬æ§åˆ¶
    '.git',
    '.svn',
    '.hg',
    
    # IDE é…ç½®
    '.idea',
    '.vscode',
    '.vs',
    '*.code-workspace',
    '.eclipse',
    '.settings',
    
    # å…¶ä»–
    '.cache',
    'tmp', 'temp',
    'logs',
    '__MACOSX',
]

# [æ–‡æœ¬è¯»å–é…ç½®]
# æ–‡æœ¬è§£ç å°è¯•çš„ç¼–ç åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
TEXT_ENCODINGS = [
    ('utf-8-sig', 'ignore'),
    ('gb18030', 'ignore'),
]

# [è¯­è¨€ç‰¹å®šæ³¨é‡Šç¬¦å·]
# ç”¨äºåœ¨åˆå¹¶æ–‡ä»¶å¤´éƒ¨æ ‡è®°æ–‡ä»¶è·¯å¾„æ—¶ä½¿ç”¨ç›¸åº”è¯­è¨€çš„æ³¨é‡Šç¬¦å·
COMMENT_MARKERS = {
    # Python
    '.py': '#',
    '.pyw': '#',
    '.pyi': '#',
    
    # JavaScript/TypeScript
    '.js': '//',
    '.jsx': '//',
    '.ts': '//',
    '.tsx': '//',
    '.mjs': '//',
    '.cjs': '//',
    
    # Java/C/C++/C#
    '.java': '//',
    '.c': '//',
    '.cpp': '//',
    '.cc': '//',
    '.cxx': '//',
    '.h': '//',
    '.hpp': '//',
    '.cs': '//',
    '.go': '//',
    '.rs': '//',
    '.swift': '//',
    '.kt': '//',
    '.scala': '//',
    
    # Shell scripts
    '.sh': '#',
    '.bash': '#',
    '.zsh': '#',
    
    # Batch/PowerShell
    '.bat': 'REM',
    '.cmd': 'REM',
    '.ps1': '#',
    
    # SQL
    '.sql': '--',
    
    # HTML/XML
    '.html': '<!--',
    '.htm': '<!--',
    '.xml': '<!--',
    
    # CSS
    '.css': '/*',
    '.scss': '//',
    '.sass': '//',
    '.less': '//',
    
    # Ruby
    '.rb': '#',
    
    # PHP
    '.php': '//',
    
    # Lua
    '.lua': '--',
    
    # R
    '.r': '#',
    '.R': '#',
    
    # Perl
    '.pl': '#',
    '.pm': '#',
    
    # YAML/TOML
    '.yaml': '#',
    '.yml': '#',
    '.toml': '#',
    
    # Configuration files
    '.ini': '#',
    '.conf': '#',
    '.config': '#',
    
    # Markdown
    '.md': '<!--',
    '.markdown': '<!--',
}

# --- ç»“æ„åŒ–ç»“æœå®šä¹‰ ---
class Status(Enum):
    TEXT_SUCCESS = auto()
    NON_TEXT = auto()
    SKIPPED_LARGE = auto()
    SKIPPED_NOT_WHITELISTED = auto() # æ›¿æ¢äº† SKIPPED_TEMP
    SKIPPED_EXCLUDED_PATH = auto()
    FAILED = auto()

@dataclass
class ProcessResult:
    path: str
    status: Status
    content: Optional[str] = None
    error_message: Optional[str] = None

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def should_exclude_path(file_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
    normalized_path = file_path.replace('\\', '/')
    path_parts = normalized_path.split('/')
    
    for excluded in EXCLUDED_PATHS:
        if '*' in excluded:
            import fnmatch
            if any(fnmatch.fnmatch(part, excluded) for part in path_parts):
                return True
        else:
            excluded_parts = excluded.split('/')
            for i in range(len(path_parts) - len(excluded_parts) + 1):
                if path_parts[i:i+len(excluded_parts)] == excluded_parts:
                    return True
    
    return False

def should_exclude_directory(dir_path: str) -> bool:
    """æ£€æŸ¥ç›®å½•æ˜¯å¦åº”è¯¥è¢«æ’é™¤ï¼ˆç”¨äºos.walkçš„ç›®å½•è¿‡æ»¤ï¼‰"""
    return should_exclude_path(dir_path)

def is_allowed_extension(file_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å…è®¸çš„ç™½åå•åˆ—è¡¨ä¸­"""
    _, ext = os.path.splitext(file_path)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ‰©å±•å
    if not ext:
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®Šæ–‡ä»¶åï¼ˆå¦‚ Dockerfileï¼‰åœ¨ç™½åå•ä¸­
        filename = os.path.basename(file_path)
        if filename in FORCE_TEXT_EXTENSIONS:
            return True
        return '*' in FORCE_TEXT_EXTENSIONS
    
    return ext.lower() in FORCE_TEXT_EXTENSIONS

def get_comment_marker(file_path: str) -> str:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–ç›¸åº”çš„æ³¨é‡Šç¬¦å·"""
    _, ext = os.path.splitext(file_path)
    ext_lower = ext.lower()
    
    marker = COMMENT_MARKERS.get(ext_lower, '#')
    
    # å¯¹äºéœ€è¦é—­åˆçš„æ³¨é‡Šç¬¦å·ï¼Œåªè¿”å›å¼€å§‹ç¬¦å·
    if marker in ['<!--', '/*']:
        return marker
    
    return marker

def format_file_header(file_path: str) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤´éƒ¨ï¼Œä½¿ç”¨è¯­è¨€ç‰¹å®šçš„æ³¨é‡Šç¬¦å·ï¼Œå¹¶åŒ…å«ä¿®æ”¹æ—¶é—´"""
    comment = get_comment_marker(file_path)
    separator = '=' * 60
    
    # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
    try:
        mtime = os.path.getmtime(file_path)
        modified_time = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')
    except Exception:
        modified_time = "Unknown"
    
    if comment == '<!--':
        return f"<!-- {separator}\n     FILE: {file_path}\n     MODIFIED: {modified_time}\n     {separator} -->\n"
    elif comment == '/*':
        return f"/* {separator}\n   FILE: {file_path}\n   MODIFIED: {modified_time}\n   {separator} */\n"
    else:
        return f"{comment} {separator}\n{comment} FILE: {file_path}\n{comment} MODIFIED: {modified_time}\n{comment} {separator}\n"

def analyze_file(file_path: str) -> ProcessResult:
    """åˆ†æå•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰ä¿¡æ¯çš„ ProcessResult å¯¹è±¡ã€‚"""
    try:
        # 1. æ£€æŸ¥æ’é™¤è·¯å¾„
        if should_exclude_path(file_path):
            return ProcessResult(path=file_path, status=Status.SKIPPED_EXCLUDED_PATH)
        
        # 2. æ£€æŸ¥ç™½åå• (ç™½åå•æ¨¡å¼)
        if not is_allowed_extension(file_path):
            return ProcessResult(path=file_path, status=Status.SKIPPED_NOT_WHITELISTED)
        
        # 3. æ£€æŸ¥æ–‡ä»¶å¤§å°
        if os.path.getsize(file_path) > MAX_FILE_SIZE_BYTES:
            return ProcessResult(path=file_path, status=Status.SKIPPED_LARGE)

        content = None
        decode_success = False
        
        # å°è¯•å¤šç§ç¼–ç è¯»å–æ–‡ä»¶
        for encoding, errors in TEXT_ENCODINGS:
            try:
                with open(file_path, "r", encoding=encoding, errors=errors) as f:
                    content = f.read()
                    decode_success = True
                    break
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        # å¦‚æœè§£ç å¤±è´¥ï¼Œç”±äºæ˜¯ç™½åå•æ¨¡å¼ï¼Œé€šå¸¸ä¸å†å¼ºè¡Œå°è¯•ï¼Œé™¤éç¡®å®éœ€è¦
        # ä½†ä¸ºäº†ç¨³å¥æ€§ï¼Œå¦‚æœè§£ç å®Œå…¨å¤±è´¥ï¼ˆä¾‹å¦‚äºŒè¿›åˆ¶ï¼‰ï¼Œå³ä½¿åœ¨ç™½åå•ä¹Ÿå¯èƒ½æ— æ³•è¯»å–
        if not decode_success:
            # å°è¯•æœ€åä¸€æ¬¡å¼ºåˆ¶ utf-8 æ›¿æ¢é”™è¯¯
            try:
                with open(file_path, "r", encoding='utf-8', errors='replace') as f:
                    content = f.read()
                    decode_success = True
            except Exception:
                pass
        
        if not decode_success:
            return ProcessResult(path=file_path, status=Status.NON_TEXT)

        return ProcessResult(path=file_path, status=Status.TEXT_SUCCESS, content=content)

    except (PermissionError, FileNotFoundError) as e:
        return ProcessResult(path=file_path, status=Status.FAILED, error_message=str(e))
    except Exception as e:
        return ProcessResult(path=file_path, status=Status.NON_TEXT, error_message=str(e))

def truncate_path(path: str, max_len: int) -> str:
    """å¦‚æœè·¯å¾„è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œåˆ™åœ¨ä¸­é—´ç”¨...ç¼©çŸ­å®ƒã€‚"""
    if len(path) <= max_len:
        return path
    
    total_chars_to_keep = max_len - 3
    head_len = total_chars_to_keep // 2
    tail_len = total_chars_to_keep - head_len
    
    head = path[:head_len]
    tail = path[-tail_len:]
    
    return f"{head}...{tail}"

def get_desktop_path() -> str:
    """è·å–æ¡Œé¢è·¯å¾„"""
    if sys.platform == 'win32':
        import winreg
        try:
            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER,
                                r'Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders')
            desktop_path = winreg.QueryValueEx(key, 'Desktop')[0]
            winreg.CloseKey(key)
            return desktop_path
        except Exception:
            return os.path.join(os.path.expanduser('~'), 'Desktop')
    else:
        return os.path.join(os.path.expanduser('~'), 'Desktop')

def build_tree_structure(file_paths: List[str], base_path: str = None) -> str:
    """æ„å»ºç›®å½•æ ‘ç»“æ„å­—ç¬¦ä¸²"""
    if not file_paths:
        return ""
    
    # ç¡®å®šåŸºç¡€è·¯å¾„
    if base_path is None:
        if len(file_paths) == 1:
            base_path = os.path.dirname(file_paths[0])
        else:
            base_path = os.path.commonpath(file_paths)
    
    # æ„å»ºæ ‘å½¢ç»“æ„
    tree_dict = {}
    for file_path in file_paths:
        try:
            rel_path = os.path.relpath(file_path, base_path)
        except ValueError:
            rel_path = file_path
        
        parts = rel_path.split(os.sep)
        current = tree_dict
        for part in parts:
            if part not in current:
                current[part] = {}
            current = current[part]
    
    # é€’å½’ç”Ÿæˆæ ‘å½¢å­—ç¬¦ä¸²
    def generate_tree(node: dict, prefix: str = "", is_last: bool = True) -> List[str]:
        lines = []
        items = sorted(node.items(), key=lambda x: (bool(x[1]), x[0]))  # æ–‡ä»¶åœ¨å‰ï¼Œç›®å½•åœ¨å
        
        for i, (name, children) in enumerate(items):
            is_last_item = (i == len(items) - 1)
            connector = "â””â”€â”€ " if is_last_item else "â”œâ”€â”€ "
            lines.append(f"{prefix}{connector}{name}")
            
            if children:
                extension = "    " if is_last_item else "â”‚   "
                lines.extend(generate_tree(children, prefix + extension, is_last_item))
        
        return lines
    
    tree_lines = [os.path.basename(base_path) or base_path]
    tree_lines.extend(generate_tree(tree_dict))
    
    return "\n".join(tree_lines)

def analyze_file_statistics(file_paths: List[str]) -> Dict[str, int]:
    """åˆ†ææ–‡ä»¶æ‰©å±•åç»Ÿè®¡"""
    extension_count = defaultdict(int)
    
    for file_path in file_paths:
        _, ext = os.path.splitext(file_path)
        if ext:
            extension_count[ext.lower()] += 1
        else:
            extension_count['[æ— æ‰©å±•å]'] += 1
    
    # æŒ‰æ•°é‡æ’åº
    sorted_stats = dict(sorted(extension_count.items(), key=lambda x: x[1], reverse=True))
    return sorted_stats

def is_documentation_file(file_path: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡æ¡£ç±»æ–‡ä»¶ï¼ˆREADMEã€MDç­‰ï¼‰"""
    file_name = os.path.basename(file_path).lower()
    _, ext = os.path.splitext(file_path)
    
    # README æ–‡ä»¶
    if file_name.startswith('readme'):
        return True
    
    # Markdown æ–‡ä»¶
    if ext.lower() in ['.md', '.markdown']:
        return True
    
    return False

def sort_files_by_priority(results: List['ProcessResult']) -> List['ProcessResult']:
    """æŒ‰ä¼˜å…ˆçº§æ’åºæ–‡ä»¶ï¼šä»£ç æ–‡ä»¶åœ¨å‰ï¼Œæ–‡æ¡£æ–‡ä»¶åœ¨å"""
    code_files = []
    doc_files = []
    
    for result in results:
        if is_documentation_file(result.path):
            doc_files.append(result)
        else:
            code_files.append(result)
    
    # åˆ†åˆ«æŒ‰è·¯å¾„æ’åºï¼Œä¿æŒç¨³å®šæ€§
    code_files.sort(key=lambda x: x.path)
    doc_files.sort(key=lambda x: x.path)
    
    return code_files + doc_files

# --- ä¸»ç¨‹åº ---

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: è¯·å°†ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹æ‹–æ‹½åˆ° .bat æ–‡ä»¶ä¸Šã€‚")
        time.sleep(3)
        return

    print("--- æ­£åœ¨å‘ç°æ–‡ä»¶... ---")
    paths_to_process = []
    processed_paths = set()
    for path_arg in sys.argv[1:]:
        abs_path = os.path.abspath(path_arg)
        if abs_path in processed_paths:
            continue
        
        if os.path.isfile(abs_path):
            processed_paths.add(abs_path)
            paths_to_process.append(abs_path)
        elif os.path.isdir(abs_path):
            for root, dirs, files in os.walk(abs_path):
                # è¿‡æ»¤æ‰åº”è¯¥æ’é™¤çš„ç›®å½•ï¼Œé¿å…è¿›å…¥éå†
                dirs[:] = [d for d in dirs if not should_exclude_directory(os.path.join(root, d))]
                
                for file_name in files:
                    file_path = os.path.join(root, file_name)
                    if file_path not in processed_paths:
                        processed_paths.add(file_path)
                        paths_to_process.append(file_path)

    if not paths_to_process:
        print("æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶è¿›è¡Œå¤„ç†ã€‚")
        return

    start_time = time.monotonic()
    
    results: List[ProcessResult] = []
    with ThreadPoolExecutor() as executor:
        future_to_path = {executor.submit(analyze_file, path): path for path in paths_to_process}
        
        print(f"\n--- å¼€å§‹å¤„ç† {len(paths_to_process)} ä¸ªæ–‡ä»¶ ---\n")
        for future in as_completed(future_to_path):
            res = future.result()
            
            # å¯¹äºæ’é™¤è·¯å¾„çš„æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
            if res.status == Status.SKIPPED_EXCLUDED_PATH:
                results.append(res)
                continue
            
            status_map = {
                Status.TEXT_SUCCESS: "âœ”  æˆåŠŸ (æ–‡æœ¬)",
                Status.NON_TEXT: "ğŸ–¼  è·³è¿‡ (éæ–‡æœ¬)",
                Status.SKIPPED_LARGE: "ğŸŸ¡ è·³è¿‡ (æ–‡ä»¶è¿‡å¤§)",
                Status.SKIPPED_NOT_WHITELISTED: "âšª è·³è¿‡ (æœªåœ¨ç™½åå•)",
                Status.FAILED: f"âŒ å¤±è´¥ ({res.error_message})"
            }
            status_str = status_map.get(res.status, "æœªçŸ¥çŠ¶æ€")
            
            # å¦‚æœæ˜¯ç™½åå•è·³è¿‡ï¼Œå¯ä»¥é€‰æ‹©ä¸æ‰“å°ä»¥å‡å°‘å™ªéŸ³ï¼Œä½†ä¸ºäº†æ˜ç¡®åé¦ˆï¼Œè¿™é‡Œè¿˜æ˜¯æ‰“å°
            display_path = truncate_path(res.path, MAX_PATH_DISPLAY_LEN)
            print(f"{display_path} ===> {status_str}")
            
            results.append(res)

    end_time = time.monotonic()
    total_duration = end_time - start_time

    # --- ç»“æœèšåˆä¸æŠ¥å‘Š ---
    text_results = []
    failed_files = []
    skipped_large_files = []
    skipped_not_whitelisted = []
    skipped_excluded_files = []
    non_text_files_count = 0

    for res in results:
        if res.status == Status.TEXT_SUCCESS:
            text_results.append(res)
        elif res.status == Status.FAILED:
            failed_files.append((res.path, res.error_message))
        elif res.status == Status.SKIPPED_LARGE:
            skipped_large_files.append(res.path)
        elif res.status == Status.SKIPPED_NOT_WHITELISTED:
            skipped_not_whitelisted.append(res.path)
        elif res.status == Status.SKIPPED_EXCLUDED_PATH:
            skipped_excluded_files.append(res.path)
        else:
            non_text_files_count += 1
    
    if text_results:
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šä»£ç æ–‡ä»¶åœ¨å‰ï¼Œæ–‡æ¡£åœ¨å
        sorted_results = sort_files_by_priority(text_results)
        
        # ç”Ÿæˆé¡¹ç›®ç»Ÿè®¡ä¿¡æ¯
        all_paths = [res.path for res in sorted_results]
        
        # ç¡®å®šåŸºç¡€è·¯å¾„
        if len(all_paths) == 1:
            base_path = os.path.dirname(all_paths[0])
        else:
            base_path = os.path.commonpath(all_paths)
        
        tree_structure = build_tree_structure(all_paths, base_path)
        file_stats = analyze_file_statistics(all_paths)
        
        # æ„å»ºç»Ÿè®¡ä¿¡æ¯å¤´éƒ¨
        stats_header = "=" * 80 + "\n"
        stats_header += "PROJECT ANALYSIS SUMMARY\n"
        stats_header += "=" * 80 + "\n\n"
        stats_header += f"Base Path: {base_path}\n"
        stats_header += f"Total Files: {len(all_paths)}\n"
        stats_header += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        stats_header += "File Type Distribution:\n"
        stats_header += "-" * 40 + "\n"
        for ext, count in file_stats.items():
            stats_header += f"  {ext:20s} : {count:4d} files\n"
        
        stats_header += "\n" + "=" * 80 + "\n"
        stats_header += "DIRECTORY STRUCTURE\n"
        stats_header += "=" * 80 + "\n\n"
        stats_header += tree_structure + "\n\n"
        stats_header += "=" * 80 + "\n"
        stats_header += "FILE CONTENTS\n"
        stats_header += "=" * 80 + "\n\n"
        
        # åˆå¹¶æ–‡ä»¶å†…å®¹
        merged_texts = [f"{format_file_header(res.path)}{res.content}\n{'-'*60}\n" 
                       for res in sorted_results]
        final_text = stats_header + "\n".join(merged_texts)
        clean_text = final_text.replace('\x00', '')
        
        # ç»Ÿè®¡å­—ç¬¦æ•°
        total_chars = len(clean_text)
        
        # ç”Ÿæˆæ¡Œé¢æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        desktop_path = get_desktop_path()
        output_file = os.path.join(desktop_path, f"{timestamp}.txt")
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(clean_text)
            print(f"\nâœ… å·²ç”Ÿæˆæ–‡ä»¶: {output_file}")
        except Exception as e:
            print(f"\nâŒ æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")
        
        # å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if PYPERCLIP_AVAILABLE:
            try:
                pyperclip.copy(clean_text)
                print("âœ… å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
            except Exception as e:
                print(f"âš ï¸  å‰ªè´´æ¿å¤åˆ¶å¤±è´¥: {e}")
        else:
            print("â„¹ï¸  æœªå®‰è£… pyperclip æ¨¡å—ï¼Œè·³è¿‡å‰ªè´´æ¿å¤åˆ¶")
    else:
        print("\nâ„¹ï¸ æœªå¤„ç†ä»»ä½•æœ‰æ•ˆæ–‡æœ¬å†…å®¹ã€‚")

    print("\n----- å¤„ç†æŠ¥å‘Š -----")
    print(f"âœ”ï¸  æˆåŠŸå¤„ç†æ–‡æœ¬æ–‡ä»¶: {len(text_results)} ä¸ª")
    print(f"ğŸ“ æ€»å­—ç¬¦æ•°: {total_chars:,} å­—ç¬¦" if text_results else "")
    print(f"ğŸ”© è·³è¿‡çš„éæ–‡æœ¬æ–‡ä»¶: {non_text_files_count} ä¸ª")
    print(f"â­ï¸  å› è¿‡å¤§è€Œè·³è¿‡çš„æ–‡ä»¶: {len(skipped_large_files)} ä¸ª")
    print(f"âšª  æœªåœ¨ç™½åå•çš„æ–‡ä»¶: {len(skipped_not_whitelisted)} ä¸ª")
    print(f"â­ï¸  æ’é™¤è·¯å¾„ä¸­çš„æ–‡ä»¶: {len(skipped_excluded_files)} ä¸ª")
    print(f"âŒ å¤±è´¥çš„æ–‡ä»¶æˆ–è·¯å¾„: {len(failed_files)} ä¸ª")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_duration:.2f} ç§’")

    if skipped_large_files:
        print("\nè·³è¿‡çš„å¤§æ–‡ä»¶åˆ—è¡¨:")
        for path in skipped_large_files:
            print(f"  - {path}")

    if failed_files:
        print("\nå¤±è´¥çš„è·¯å¾„åˆ—è¡¨:")
        for path, reason in failed_files:
            print(f"  - {path}\n    åŸå› : {reason}")
    
    print("--------------------")

    timeout = 30 if failed_files else 5
    print(f"\nç¨‹åºå°†åœ¨ {timeout} ç§’åè‡ªåŠ¨å…³é—­...")
    time.sleep(timeout)

if __name__ == "__main__":
    main()
