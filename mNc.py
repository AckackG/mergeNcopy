# FILE: F:\program5\copyNmerge\cNm_path_optimized.py
import sys
import os
import time
import pyperclip
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from enum import Enum, auto
from typing import List, Optional

# --- å¸¸é‡å®šä¹‰ ---

# [æ˜¾ç¤ºé…ç½®]
# å®æ—¶è¾“å‡ºæ—¶ï¼Œç”¨äºæ˜¾ç¤ºæ–‡ä»¶è·¯å¾„çš„æœ€å¤§å­—ç¬¦é•¿åº¦ã€‚è¶…è¿‡æ­¤é•¿åº¦çš„è·¯å¾„ä¸­é—´ä¼šæ˜¾ç¤ºä¸º...
MAX_PATH_DISPLAY_LEN = 80

# [æ–‡ä»¶è¿‡æ»¤]
# å®šä¹‰å•ä¸ªæ–‡ä»¶çš„æœ€å¤§ä½“ç§¯ï¼ˆ20MBï¼‰ã€‚è¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶å°†è¢«ç›´æ¥è·³è¿‡ï¼Œä¸è¿›è¡Œä»»ä½•è¯»å–æˆ–åˆ†æã€‚
# ç›®çš„æ˜¯ä¸ºäº†é˜²æ­¢å› æ„å¤–æ‹–å…¥è¶…å¤§æ–‡ä»¶ï¼ˆå¦‚è§†é¢‘ã€æ•°æ®åº“ï¼‰å¯¼è‡´ç¨‹åºå†…å­˜æº¢å‡ºæˆ–é•¿æ—¶é—´æ— å“åº”ã€‚
MAX_FILE_SIZE_BYTES = 20 * 1024 * 1024

# [æ™ºèƒ½è¯†åˆ«é€»è¾‘]
# å¯¹äºå…·æœ‰å¯ç–‘æ‰©å±•åï¼ˆå¦‚.docx, .pdfï¼‰çš„æ–‡ä»¶ï¼Œå³ä½¿æˆåŠŸè§£ç ä¸ºæ–‡æœ¬ï¼Œ
# å¦‚æœå…¶å†…å®¹é•¿åº¦å°äºæ­¤å€¼ï¼ˆ30ä¸ªå­—ç¬¦ï¼‰ï¼Œæˆ‘ä»¬ä»ç„¶è®¤ä¸ºå®ƒæ˜¯ä¸€æ¬¡é”™è¯¯çš„è§£ç ï¼Œå¹¶å°†å…¶å½’ç±»ä¸ºéæ–‡æœ¬æ–‡ä»¶ã€‚
# ç›®çš„æ˜¯è¿‡æ»¤æ‰é‚£äº›äºŒè¿›åˆ¶æ–‡ä»¶å¤´éƒ¨æ°å¥½èƒ½è¢«è§£ç æˆä¸€å°æ®µæ— æ„ä¹‰æ–‡æœ¬çš„æƒ…å†µã€‚
MIN_SUSPICIOUS_TEXT_LEN = 30

# ä¹±ç æ£€æµ‹é˜ˆå€¼ã€‚åœ¨æ–‡ä»¶å¤´éƒ¨çš„æ ·æœ¬ä¸­ï¼Œå¦‚æœä¸å¯æ‰“å°å­—ç¬¦ï¼ˆé™¤æ¢è¡Œã€åˆ¶è¡¨ç¬¦å¤–ï¼‰çš„æ¯”ä¾‹è¶…è¿‡5%ï¼Œ
# åˆ™è¯¥æ–‡ä»¶è¢«åˆ¤å®šä¸ºäºŒè¿›åˆ¶/ä¹±ç æ–‡ä»¶ã€‚è¿™ä¸ªå€¼å¯ä»¥æ ¹æ®éœ€è¦å¾®è°ƒï¼Œå€¼è¶Šä½è¶Šä¸¥æ ¼ã€‚
NON_PRINTABLE_THRESHOLD = 0.05

# è¿›è¡Œä¹±ç æ£€æµ‹æ—¶ï¼Œä»æ–‡ä»¶å¤´éƒ¨è¯»å–çš„æ ·æœ¬å¤§å°ï¼ˆ8KBï¼‰ã€‚
# æˆ‘ä»¬ä»…æ£€æŸ¥è¿™éƒ¨åˆ†å†…å®¹æ¥åˆ¤æ–­æ–‡ä»¶ç±»å‹ï¼Œè€Œä¸æ˜¯è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼Œè¿™æå¤§åœ°æé«˜äº†å¤„ç†å¤§æ–‡ä»¶æ—¶çš„æ€§èƒ½ã€‚
GARBAGE_CHECK_SAMPLE_SIZE = 8192

# åªæœ‰å½“è¯»å–åˆ°çš„æ–‡æœ¬æ ·æœ¬é•¿åº¦è¶…è¿‡æ­¤å€¼ï¼ˆ100ä¸ªå­—ç¬¦ï¼‰æ—¶ï¼Œæ‰å¯åŠ¨ä¹±ç æ£€æµ‹ã€‚
# è¿™æ˜¯ä¸ºäº†é˜²æ­¢å¯¹æœ¬èº«å†…å®¹å°±å¾ˆå°‘çš„çŸ­æ–‡æœ¬æ–‡ä»¶ï¼ˆå¦‚åªæœ‰ä¸€ä¸ªå•è¯çš„txtï¼‰è¿›è¡Œè¯¯åˆ¤ã€‚
GARBAGE_CHECK_MIN_LEN = 100

# --- ---- ---

SUSPICIOUS_EXTENSIONS = {
    '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.jpg', 
    '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.svg', '.mp3', 
    '.wav', '.mp4', '.mkv', '.avi', '.mov', '.flv', '.zip', '.rar', 
    '.7z', '.tar', '.gz', '.exe', '.dll', '.so', '.bin', '.iso', '.dat', '.db'
}

# --- ç»“æ„åŒ–ç»“æœå®šä¹‰ ---
class Status(Enum):
    TEXT_SUCCESS = auto()
    NON_TEXT = auto()
    SKIPPED_LARGE = auto()
    SKIPPED_SUSPICIOUS_SHORT = auto()
    FAILED = auto()

@dataclass
class ProcessResult:
    path: str
    status: Status
    content: Optional[str] = None
    error_message: Optional[str] = None

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def is_likely_garbage_text(text_sample: str) -> bool:
    """é€šè¿‡è®¡ç®—ä¸å¯æ‰“å°å­—ç¬¦çš„æ¯”ä¾‹æ¥åˆ¤æ–­æ–‡æœ¬æ ·æœ¬æ˜¯å¦ä¸ºäºŒè¿›åˆ¶ä¹±ç ã€‚"""
    if len(text_sample) < GARBAGE_CHECK_MIN_LEN:
        return False
    
    non_printable_count = sum(1 for char in text_sample if not char.isprintable() and char not in '\n\r\t')
    ratio = non_printable_count / len(text_sample)
    return ratio > NON_PRINTABLE_THRESHOLD

def analyze_file(file_path: str) -> ProcessResult:
    """åˆ†æå•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰ä¿¡æ¯çš„ ProcessResult å¯¹è±¡ã€‚"""
    try:
        if os.path.getsize(file_path) > MAX_FILE_SIZE_BYTES:
            return ProcessResult(path=file_path, status=Status.SKIPPED_LARGE)

        content = None
        try:
            with open(file_path, "r", encoding="utf-8-sig") as f:
                sample = f.read(GARBAGE_CHECK_SAMPLE_SIZE)
                if is_likely_garbage_text(sample):
                    return ProcessResult(path=file_path, status=Status.NON_TEXT)
                content = sample + f.read()
        except UnicodeDecodeError:
            with open(file_path, "r", encoding="gb18030", errors="ignore") as f:
                sample = f.read(GARBAGE_CHECK_SAMPLE_SIZE)
                if is_likely_garbage_text(sample):
                    return ProcessResult(path=file_path, status=Status.NON_TEXT)
                content = sample + f.read()
        
        _, extension = os.path.splitext(file_path)
        is_suspicious = extension.lower() in SUSPICIOUS_EXTENSIONS
        if is_suspicious and len(content) < MIN_SUSPICIOUS_TEXT_LEN:
            return ProcessResult(path=file_path, status=Status.SKIPPED_SUSPICIOUS_SHORT)

        return ProcessResult(path=file_path, status=Status.TEXT_SUCCESS, content=content)

    except (PermissionError, FileNotFoundError) as e:
        return ProcessResult(path=file_path, status=Status.FAILED, error_message=str(e))
    except Exception as e:
        return ProcessResult(path=file_path, status=Status.NON_TEXT, error_message=str(e))

# --- æ–°å¢ï¼šè·¯å¾„æ ¼å¼åŒ–è¾…åŠ©å‡½æ•° ---
def truncate_path(path: str, max_len: int) -> str:
    """å¦‚æœè·¯å¾„è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œåˆ™åœ¨ä¸­é—´ç”¨...ç¼©çŸ­å®ƒã€‚"""
    if len(path) <= max_len:
        return path
    
    # ä¸º "..." ç•™å‡º3ä¸ªå­—ç¬¦
    total_chars_to_keep = max_len - 3
    head_len = total_chars_to_keep // 2
    tail_len = total_chars_to_keep - head_len
    
    head = path[:head_len]
    tail = path[-tail_len:]
    
    return f"{head}...{tail}"

# --- ä¸»ç¨‹åº ---

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: è¯·å°†ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹æ‹–æ‹½åˆ° .bat æ–‡ä»¶ä¸Šã€‚")
        time.sleep(3)
        return

    print("--- æ­£åœ¨å‘ç°æ–‡ä»¶... ---")
    paths_to_process = []
    processed_paths = set()
    for path_arg in sys.argv[1:]:
        abs_path = os.path.abspath(path_arg)
        if abs_path in processed_paths:
            continue
        
        if os.path.isfile(abs_path):
            processed_paths.add(abs_path)
            paths_to_process.append(abs_path)
        elif os.path.isdir(abs_path):
            for root, _, files in os.walk(abs_path):
                for file_name in files:
                    file_path = os.path.join(root, file_name)
                    if file_path not in processed_paths:
                        processed_paths.add(file_path)
                        paths_to_process.append(file_path)

    if not paths_to_process:
        print("æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶è¿›è¡Œå¤„ç†ã€‚")
        return

    start_time = time.monotonic()
    
    results: List[ProcessResult] = []
    with ThreadPoolExecutor() as executor:
        future_to_path = {executor.submit(analyze_file, path): path for path in paths_to_process}
        
        print(f"\n--- å¼€å§‹å¤„ç† {len(paths_to_process)} ä¸ªæ–‡ä»¶ ---\n")
        for future in as_completed(future_to_path):
            res = future.result()
            
            status_map = {
                Status.TEXT_SUCCESS: "âœ”  æˆåŠŸ (æ–‡æœ¬)",
                Status.NON_TEXT: "ğŸ–¼  æˆåŠŸ (äºŒè¿›åˆ¶)",
                Status.SKIPPED_LARGE: "ğŸŸ¡  è·³è¿‡ (æ–‡ä»¶è¿‡å¤§)",
                Status.SKIPPED_SUSPICIOUS_SHORT: "ğŸŸ¡  è·³è¿‡ (å¯ç–‘ä¸”å†…å®¹è¿‡çŸ­)",
                Status.FAILED: f"âŒ å¤±è´¥ ({res.error_message})"
            }
            status_str = status_map.get(res.status, "æœªçŸ¥çŠ¶æ€")
            
            # --- æ­¤å¤„æ˜¯å”¯ä¸€çš„ä¿®æ”¹ç‚¹ ---
            # ä½¿ç”¨æ–°å‡½æ•°æ ¼å¼åŒ–è·¯å¾„ç”¨äºæ˜¾ç¤º
            display_path = truncate_path(res.path, MAX_PATH_DISPLAY_LEN)
            print(f"{display_path} ===> {status_str}")
            
            results.append(res)

    end_time = time.monotonic()
    total_duration = end_time - start_time

    # --- ç»“æœèšåˆä¸æŠ¥å‘Š ---
    text_results = []
    failed_files = []
    skipped_large_files = []
    non_text_files_count = 0

    for res in results:
        if res.status == Status.TEXT_SUCCESS:
            text_results.append(res)
        elif res.status == Status.FAILED:
            failed_files.append((res.path, res.error_message))
        elif res.status == Status.SKIPPED_LARGE:
            skipped_large_files.append(res.path)
        else:
            non_text_files_count += 1
    
    if text_results:
        merged_texts = [f"===== FILE: {res.path} =====\n{res.content}\n{'-'*60}\n" for res in text_results]
        final_text = "\n".join(merged_texts)
        pyperclip.copy(final_text.replace('\x00', ''))
        print("\nâœ… å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
    else:
        print("\nâ„¹ï¸ æœªå¤„ç†ä»»ä½•æœ‰æ•ˆæ–‡æœ¬å†…å®¹ï¼Œå‰ªè´´æ¿æœªæ”¹åŠ¨ã€‚")

    print("\n----- å¤„ç†æŠ¥å‘Š -----")
    print(f"âœ”ï¸ æˆåŠŸå¤„ç†æ–‡æœ¬æ–‡ä»¶: {len(text_results)} ä¸ª")
    print(f"ğŸ”© å¤„ç†ä¸ºéæ–‡æœ¬æ–‡ä»¶: {non_text_files_count} ä¸ª")
    print(f"â­ï¸ å› è¿‡å¤§è€Œè·³è¿‡çš„æ–‡ä»¶: {len(skipped_large_files)} ä¸ª")
    print(f"âŒ å¤±è´¥çš„æ–‡ä»¶æˆ–è·¯å¾„: {len(failed_files)} ä¸ª")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_duration:.2f} ç§’")

    if skipped_large_files:
        print("\nè·³è¿‡çš„æ–‡ä»¶åˆ—è¡¨:")
        for path in skipped_large_files:
            print(f"  - {path}")

    if failed_files:
        print("\nå¤±è´¥çš„è·¯å¾„åˆ—è¡¨:")
        for path, reason in failed_files:
            print(f"  - {path}\n    åŸå› : {reason}")
    
    print("--------------------")

    timeout = 30 if failed_files else 5
    print(f"\nç¨‹åºå°†åœ¨ {timeout} ç§’åè‡ªåŠ¨å…³é—­...")
    time.sleep(timeout)

if __name__ == "__main__":
    main()
