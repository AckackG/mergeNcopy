import sys
import os
import time
import pyperclip
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from enum import Enum, auto
from typing import List, Optional

# --- å¸¸é‡å®šä¹‰ ---

# [æ˜¾ç¤ºé…ç½®]
# å®æ—¶è¾“å‡ºæ—¶ï¼Œç”¨äºæ˜¾ç¤ºæ–‡ä»¶è·¯å¾„çš„æœ€å¤§å­—ç¬¦é•¿åº¦ã€‚è¶…è¿‡æ­¤é•¿åº¦çš„è·¯å¾„ä¸­é—´ä¼šæ˜¾ç¤ºä¸º...
MAX_PATH_DISPLAY_LEN = 80

# [æ–‡ä»¶è¿‡æ»¤]
# å®šä¹‰å•ä¸ªæ–‡ä»¶çš„æœ€å¤§ä½“ç§¯ï¼ˆ20MBï¼‰ã€‚è¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶å°†è¢«ç›´æ¥è·³è¿‡ï¼Œä¸è¿›è¡Œä»»ä½•è¯»å–æˆ–åˆ†æã€‚
# ç›®çš„æ˜¯ä¸ºäº†é˜²æ­¢å› æ„å¤–æ‹–å…¥è¶…å¤§æ–‡ä»¶ï¼ˆå¦‚è§†é¢‘ã€æ•°æ®åº“ï¼‰å¯¼è‡´ç¨‹åºå†…å­˜æº¢å‡ºæˆ–é•¿æ—¶é—´æ— å“åº”ã€‚
MAX_FILE_SIZE_BYTES = 20 * 1024 * 1024

# [é¡¹ç›®ä¸´æ—¶æ–‡ä»¶è¿‡æ»¤]
# æ˜¯å¦å¿½ç•¥å¸¸è§çš„é¡¹ç›®ä¸´æ—¶æ–‡ä»¶å’Œç¼“å­˜æ–‡ä»¶
IGNORE_TEMP_FILES = True

# éœ€è¦å¿½ç•¥çš„ä¸´æ—¶æ–‡ä»¶æ¨¡å¼ï¼ˆæ–‡ä»¶åæˆ–æ‰©å±•åï¼‰
TEMP_FILE_PATTERNS = {
    # Python ä¸´æ—¶æ–‡ä»¶
    '.pyc', '.pyo', '.pyd', '__pycache__',
    # JavaScript/Node ä¸´æ—¶æ–‡ä»¶
    '.DS_Store', 'Thumbs.db',
    # ç¼–è¯‘äº§ç‰©
    '.o', '.obj', '.class',
    # æ—¥å¿—æ–‡ä»¶
    '.log',
    # ä¸´æ—¶æ–‡ä»¶
    '.tmp', '.temp', '.swp', '.swo', '~',
    # é”æ–‡ä»¶
    '.lock', 'package-lock.json', 'yarn.lock', 'poetry.lock', 'Pipfile.lock',
}

# [æ’é™¤è·¯å¾„é…ç½®]
# éœ€è¦æ’é™¤çš„ç›®å½•è·¯å¾„åˆ—è¡¨ï¼ˆæ”¯æŒå¤šçº§è·¯å¾„ï¼‰
# ä¾‹å¦‚ï¼š'venv/lib' ä¼šæ’é™¤æ‰€æœ‰ venv ç›®å½•ä¸‹çš„ lib å­ç›®å½•
# ä½†ä¸ä¼šæ’é™¤ src/lib è¿™æ ·çš„è·¯å¾„
EXCLUDED_PATHS = [
    # Python ç›¸å…³
    'venv', 'env', '.venv', '.env',
    'venv/lib', 'env/lib', '.venv/lib',
    '__pycache__',
    '.pytest_cache',
    '.tox',
    'dist', 'build',
    '*.egg-info',
    '.mypy_cache',
    '.ruff_cache',
    
    # JavaScript/Node ç›¸å…³
    'node_modules',
    '.npm',
    '.yarn',
    'bower_components',
    'dist', 'build',
    '.next',
    '.nuxt',
    'coverage',
    
    # ç‰ˆæœ¬æ§åˆ¶
    '.git',
    '.svn',
    '.hg',
    
    # IDE é…ç½®
    '.idea',
    '.vscode',
    '.vs',
    '*.code-workspace',
    
    # å…¶ä»–
    '.cache',
    'tmp', 'temp',
    'logs',
]

# [æ™ºèƒ½è¯†åˆ«é€»è¾‘]
# å¯¹äºå…·æœ‰å¯ç–‘æ‰©å±•åï¼ˆå¦‚.docx, .pdfï¼‰çš„æ–‡ä»¶ï¼Œå³ä½¿æˆåŠŸè§£ç ä¸ºæ–‡æœ¬ï¼Œ
# å¦‚æœå…¶å†…å®¹é•¿åº¦å°äºæ­¤å€¼ï¼ˆ30ä¸ªå­—ç¬¦ï¼‰ï¼Œæˆ‘ä»¬ä»ç„¶è®¤ä¸ºå®ƒæ˜¯ä¸€æ¬¡é”™è¯¯çš„è§£ç ï¼Œå¹¶å°†å…¶å½’ç±»ä¸ºéæ–‡æœ¬æ–‡ä»¶ã€‚
# ç›®çš„æ˜¯è¿‡æ»¤æ‰é‚£äº›äºŒè¿›åˆ¶æ–‡ä»¶å¤´éƒ¨æ°å¥½èƒ½è¢«è§£ç æˆä¸€å°æ®µæ— æ„ä¹‰æ–‡æœ¬çš„æƒ…å†µã€‚
MIN_SUSPICIOUS_TEXT_LEN = 30

# ä¹±ç æ£€æµ‹é˜ˆå€¼ã€‚åœ¨æ–‡ä»¶å¤´éƒ¨çš„æ ·æœ¬ä¸­ï¼Œå¦‚æœä¸å¯æ‰“å°å­—ç¬¦ï¼ˆé™¤æ¢è¡Œã€åˆ¶è¡¨ç¬¦å¤–ï¼‰çš„æ¯”ä¾‹è¶…è¿‡5%ï¼Œ
# åˆ™è¯¥æ–‡ä»¶è¢«åˆ¤å®šä¸ºäºŒè¿›åˆ¶/ä¹±ç æ–‡ä»¶ã€‚è¿™ä¸ªå€¼å¯ä»¥æ ¹æ®éœ€è¦å¾®è°ƒï¼Œå€¼è¶Šä½è¶Šä¸¥æ ¼ã€‚
NON_PRINTABLE_THRESHOLD = 0.05

# è¿›è¡Œä¹±ç æ£€æµ‹æ—¶ï¼Œä»æ–‡ä»¶å¤´éƒ¨è¯»å–çš„æ ·æœ¬å¤§å°ï¼ˆ8KBï¼‰ã€‚
# æˆ‘ä»¬ä»…æ£€æŸ¥è¿™éƒ¨åˆ†å†…å®¹æ¥åˆ¤æ–­æ–‡ä»¶ç±»å‹ï¼Œè€Œä¸æ˜¯è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼Œè¿™æå¤§åœ°æé«˜äº†å¤„ç†å¤§æ–‡ä»¶æ—¶çš„æ€§èƒ½ã€‚
GARBAGE_CHECK_SAMPLE_SIZE = 8192

# åªæœ‰å½“è¯»å–åˆ°çš„æ–‡æœ¬æ ·æœ¬é•¿åº¦è¶…è¿‡æ­¤å€¼ï¼ˆ100ä¸ªå­—ç¬¦ï¼‰æ—¶ï¼Œæ‰å¯åŠ¨ä¹±ç æ£€æµ‹ã€‚
# è¿™æ˜¯ä¸ºäº†é˜²æ­¢å¯¹æœ¬èº«å†…å®¹å°±å¾ˆå°‘çš„çŸ­æ–‡æœ¬æ–‡ä»¶ï¼ˆå¦‚åªæœ‰ä¸€ä¸ªå•è¯çš„txtï¼‰è¿›è¡Œè¯¯åˆ¤ã€‚
GARBAGE_CHECK_MIN_LEN = 100

# [é«˜çº§åŠŸèƒ½ - æ–‡æœ¬è¯»å–é…ç½®]
# å¯ç–‘çš„äºŒè¿›åˆ¶æ–‡ä»¶æ‰©å±•ååˆ—è¡¨
# è¿™äº›æ‰©å±•åçš„æ–‡ä»¶å³ä½¿èƒ½è¢«è§£ç ä¸ºæ–‡æœ¬ï¼Œä¹Ÿéœ€è¦é¢å¤–éªŒè¯
SUSPICIOUS_EXTENSIONS = {
    '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.jpg', 
    '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.svg', '.mp3', 
    '.wav', '.mp4', '.mkv', '.avi', '.mov', '.flv', '.zip', '.rar', 
    '.7z', '.tar', '.gz', '.exe', '.dll', '.so', '.bin', '.iso', '.dat', '.db'
}

# æ–‡æœ¬è§£ç å°è¯•çš„ç¼–ç åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
# é¦–å…ˆå°è¯• UTF-8ï¼ˆå¸¦ BOM å¤„ç†ï¼‰ï¼Œå¤±è´¥åå°è¯• GB18030
TEXT_ENCODINGS = [
    ('utf-8-sig', 'ignore'),  # UTF-8 with BOM handling
    ('gb18030', 'ignore'),    # Chinese encoding fallback
]

# --- ---- ---

# --- ç»“æ„åŒ–ç»“æœå®šä¹‰ ---
class Status(Enum):
    TEXT_SUCCESS = auto()
    NON_TEXT = auto()
    SKIPPED_LARGE = auto()
    SKIPPED_SUSPICIOUS_SHORT = auto()
    SKIPPED_TEMP = auto()
    SKIPPED_EXCLUDED_PATH = auto()
    FAILED = auto()

@dataclass
class ProcessResult:
    path: str
    status: Status
    content: Optional[str] = None
    error_message: Optional[str] = None

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def should_exclude_path(file_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
    # æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦
    normalized_path = file_path.replace('\\', '/')
    path_parts = normalized_path.split('/')
    
    for excluded in EXCLUDED_PATHS:
        # å¤„ç†é€šé…ç¬¦æ¨¡å¼
        if '*' in excluded:
            import fnmatch
            if any(fnmatch.fnmatch(part, excluded) for part in path_parts):
                return True
        else:
            # å¤„ç†å¤šçº§è·¯å¾„åŒ¹é…
            excluded_parts = excluded.split('/')
            
            # æ£€æŸ¥è·¯å¾„ä¸­æ˜¯å¦å­˜åœ¨è¿ç»­åŒ¹é…çš„éƒ¨åˆ†
            for i in range(len(path_parts) - len(excluded_parts) + 1):
                if path_parts[i:i+len(excluded_parts)] == excluded_parts:
                    return True
    
    return False

def is_temp_file(file_path: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºä¸´æ—¶æ–‡ä»¶"""
    if not IGNORE_TEMP_FILES:
        return False
    
    file_name = os.path.basename(file_path)
    
    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ¹é…ä¸´æ—¶æ–‡ä»¶æ¨¡å¼
    for pattern in TEMP_FILE_PATTERNS:
        if pattern.startswith('.'):
            # æ‰©å±•ååŒ¹é…
            if file_name.endswith(pattern):
                return True
        else:
            # æ–‡ä»¶ååŒ¹é…
            if file_name == pattern or pattern in file_name:
                return True
    
    # æ£€æŸ¥æ˜¯å¦ä»¥ ~ å¼€å¤´æˆ–ç»“å°¾ï¼ˆä¸´æ—¶æ–‡ä»¶å¸¸è§æ ‡è®°ï¼‰
    if file_name.startswith('~') or file_name.endswith('~'):
        return True
    
    return False

def is_likely_garbage_text(text_sample: str) -> bool:
    """é€šè¿‡è®¡ç®—ä¸å¯æ‰“å°å­—ç¬¦çš„æ¯”ä¾‹æ¥åˆ¤æ–­æ–‡æœ¬æ ·æœ¬æ˜¯å¦ä¸ºäºŒè¿›åˆ¶ä¹±ç ã€‚"""
    if len(text_sample) < GARBAGE_CHECK_MIN_LEN:
        return False
    
    non_printable_count = sum(1 for char in text_sample if not char.isprintable() and char not in '\n\r\t')
    ratio = non_printable_count / len(text_sample)
    return ratio > NON_PRINTABLE_THRESHOLD

def analyze_file(file_path: str) -> ProcessResult:
    """åˆ†æå•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰ä¿¡æ¯çš„ ProcessResult å¯¹è±¡ã€‚"""
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ’é™¤è·¯å¾„
        if should_exclude_path(file_path):
            return ProcessResult(path=file_path, status=Status.SKIPPED_EXCLUDED_PATH)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸´æ—¶æ–‡ä»¶
        if is_temp_file(file_path):
            return ProcessResult(path=file_path, status=Status.SKIPPED_TEMP)
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if os.path.getsize(file_path) > MAX_FILE_SIZE_BYTES:
            return ProcessResult(path=file_path, status=Status.SKIPPED_LARGE)

        content = None
        decode_success = False
        
        # å°è¯•å¤šç§ç¼–ç è¯»å–æ–‡ä»¶
        for encoding, errors in TEXT_ENCODINGS:
            try:
                with open(file_path, "r", encoding=encoding, errors=errors) as f:
                    sample = f.read(GARBAGE_CHECK_SAMPLE_SIZE)
                    if is_likely_garbage_text(sample):
                        return ProcessResult(path=file_path, status=Status.NON_TEXT)
                    content = sample + f.read()
                    decode_success = True
                    break
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œæ ‡è®°ä¸ºéæ–‡æœ¬
        if not decode_success:
            return ProcessResult(path=file_path, status=Status.NON_TEXT)
        
        # æ£€æŸ¥å¯ç–‘æ‰©å±•åæ–‡ä»¶çš„å†…å®¹é•¿åº¦
        _, extension = os.path.splitext(file_path)
        is_suspicious = extension.lower() in SUSPICIOUS_EXTENSIONS
        if is_suspicious and len(content) < MIN_SUSPICIOUS_TEXT_LEN:
            return ProcessResult(path=file_path, status=Status.SKIPPED_SUSPICIOUS_SHORT)

        return ProcessResult(path=file_path, status=Status.TEXT_SUCCESS, content=content)

    except (PermissionError, FileNotFoundError) as e:
        return ProcessResult(path=file_path, status=Status.FAILED, error_message=str(e))
    except Exception as e:
        return ProcessResult(path=file_path, status=Status.NON_TEXT, error_message=str(e))

# --- è·¯å¾„æ ¼å¼åŒ–è¾…åŠ©å‡½æ•° ---
def truncate_path(path: str, max_len: int) -> str:
    """å¦‚æœè·¯å¾„è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œåˆ™åœ¨ä¸­é—´ç”¨...ç¼©çŸ­å®ƒã€‚"""
    if len(path) <= max_len:
        return path
    
    # ä¸º "..." ç•™å‡º3ä¸ªå­—ç¬¦
    total_chars_to_keep = max_len - 3
    head_len = total_chars_to_keep // 2
    tail_len = total_chars_to_keep - head_len
    
    head = path[:head_len]
    tail = path[-tail_len:]
    
    return f"{head}...{tail}"

# --- ä¸»ç¨‹åº ---

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: è¯·å°†ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹æ‹–æ‹½åˆ° .bat æ–‡ä»¶ä¸Šã€‚")
        time.sleep(3)
        return

    print("--- æ­£åœ¨å‘ç°æ–‡ä»¶... ---")
    paths_to_process = []
    processed_paths = set()
    for path_arg in sys.argv[1:]:
        abs_path = os.path.abspath(path_arg)
        if abs_path in processed_paths:
            continue
        
        if os.path.isfile(abs_path):
            processed_paths.add(abs_path)
            paths_to_process.append(abs_path)
        elif os.path.isdir(abs_path):
            for root, _, files in os.walk(abs_path):
                for file_name in files:
                    file_path = os.path.join(root, file_name)
                    if file_path not in processed_paths:
                        processed_paths.add(file_path)
                        paths_to_process.append(file_path)

    if not paths_to_process:
        print("æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶è¿›è¡Œå¤„ç†ã€‚")
        return

    start_time = time.monotonic()
    
    results: List[ProcessResult] = []
    with ThreadPoolExecutor() as executor:
        future_to_path = {executor.submit(analyze_file, path): path for path in paths_to_process}
        
        print(f"\n--- å¼€å§‹å¤„ç† {len(paths_to_process)} ä¸ªæ–‡ä»¶ ---\n")
        for future in as_completed(future_to_path):
            res = future.result()
            
            status_map = {
                Status.TEXT_SUCCESS: "âœ”  æˆåŠŸ (æ–‡æœ¬)",
                Status.NON_TEXT: "ğŸ–¼  æˆåŠŸ (äºŒè¿›åˆ¶)",
                Status.SKIPPED_LARGE: "ğŸŸ¡ è·³è¿‡ (æ–‡ä»¶è¿‡å¤§)",
                Status.SKIPPED_SUSPICIOUS_SHORT: "ğŸŸ¡ è·³è¿‡ (å¯ç–‘ä¸”å†…å®¹è¿‡çŸ­)",
                Status.SKIPPED_TEMP: "â­ï¸  è·³è¿‡ (ä¸´æ—¶æ–‡ä»¶)",
                Status.SKIPPED_EXCLUDED_PATH: "â­ï¸  è·³è¿‡ (æ’é™¤è·¯å¾„)",
                Status.FAILED: f"âŒ å¤±è´¥ ({res.error_message})"
            }
            status_str = status_map.get(res.status, "æœªçŸ¥çŠ¶æ€")
            
            display_path = truncate_path(res.path, MAX_PATH_DISPLAY_LEN)
            print(f"{display_path} ===> {status_str}")
            
            results.append(res)

    end_time = time.monotonic()
    total_duration = end_time - start_time

    # --- ç»“æœèšåˆä¸æŠ¥å‘Š ---
    text_results = []
    failed_files = []
    skipped_large_files = []
    skipped_temp_files = []
    skipped_excluded_files = []
    non_text_files_count = 0

    for res in results:
        if res.status == Status.TEXT_SUCCESS:
            text_results.append(res)
        elif res.status == Status.FAILED:
            failed_files.append((res.path, res.error_message))
        elif res.status == Status.SKIPPED_LARGE:
            skipped_large_files.append(res.path)
        elif res.status == Status.SKIPPED_TEMP:
            skipped_temp_files.append(res.path)
        elif res.status == Status.SKIPPED_EXCLUDED_PATH:
            skipped_excluded_files.append(res.path)
        else:
            non_text_files_count += 1
    
    if text_results:
        merged_texts = [f"===== FILE: {res.path} =====\n{res.content}\n{'-'*60}\n" for res in text_results]
        final_text = "\n".join(merged_texts)
        pyperclip.copy(final_text.replace('\x00', ''))
        print("\nâœ… å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
    else:
        print("\nâ„¹ï¸ æœªå¤„ç†ä»»ä½•æœ‰æ•ˆæ–‡æœ¬å†…å®¹ï¼Œå‰ªè´´æ¿æœªæ”¹åŠ¨ã€‚")

    print("\n----- å¤„ç†æŠ¥å‘Š -----")
    print(f"âœ”ï¸  æˆåŠŸå¤„ç†æ–‡æœ¬æ–‡ä»¶: {len(text_results)} ä¸ª")
    print(f"ğŸ”© å¤„ç†ä¸ºéæ–‡æœ¬æ–‡ä»¶: {non_text_files_count} ä¸ª")
    print(f"â­ï¸  å› è¿‡å¤§è€Œè·³è¿‡çš„æ–‡ä»¶: {len(skipped_large_files)} ä¸ª")
    print(f"â­ï¸  è·³è¿‡çš„ä¸´æ—¶æ–‡ä»¶: {len(skipped_temp_files)} ä¸ª")
    print(f"â­ï¸  æ’é™¤è·¯å¾„ä¸­çš„æ–‡ä»¶: {len(skipped_excluded_files)} ä¸ª")
    print(f"âŒ å¤±è´¥çš„æ–‡ä»¶æˆ–è·¯å¾„: {len(failed_files)} ä¸ª")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_duration:.2f} ç§’")

    if skipped_large_files:
        print("\nè·³è¿‡çš„å¤§æ–‡ä»¶åˆ—è¡¨:")
        for path in skipped_large_files:
            print(f"  - {path}")

    if failed_files:
        print("\nå¤±è´¥çš„è·¯å¾„åˆ—è¡¨:")
        for path, reason in failed_files:
            print(f"  - {path}\n    åŸå› : {reason}")
    
    print("--------------------")

    timeout = 30 if failed_files else 5
    print(f"\nç¨‹åºå°†åœ¨ {timeout} ç§’åè‡ªåŠ¨å…³é—­...")
    time.sleep(timeout)

if __name__ == "__main__":
    main()
